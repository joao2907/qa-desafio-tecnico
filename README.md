# Desafio TÃ©cnico QA

Este repositÃ³rio contÃ©m a soluÃ§Ã£o desenvolvida para o **Desafio TÃ©cnico de QA**. 
O projeto inclui automaÃ§Ã£o de testes Web e API, testes de performance e documentaÃ§Ã£o de apoio. 
Foram realizados testes **manuais e automatizados** nas seguintes aplicaÃ§Ãµes pÃºblicas:

- ğŸŒ **Web (Automation Testing Demo)** â€” testes de cadastro, login, formulÃ¡rios, upload, alertas e iframes.  
- ğŸ”— **API (DummyJSON)** â€” testes de produtos e usuÃ¡rios (CRUD + validaÃ§Ã£o de contrato).  
- âš¡ **Performance (JSONPlaceholder)** â€” teste de carga no endpoint `/posts`.  

O projeto inclui:  
- ğŸ“‹ Plano de Testes detalhado  
- ğŸ“ Casos de teste manuais  
- ğŸ¤– AutomaÃ§Ã£o Web e API em Java  
- âš¡ Testes de performance com k6   

---

## ğŸ“‹ Plano de Testes
O **Plano de Testes completo** estÃ¡ disponÃ­vel em:  
â¡ï¸ Plano de testes.docx

---

## ğŸ“‘ RelatÃ³rio Final
Este relatÃ³rio apresenta as atividades realizadas durante o desafio tÃ©cnico, contemplando **testes de API (DummyJSON)**, **testes Web (Automation Testing Demo)** e **testes de performance (JSONPlaceholder)**.  
â¡ï¸ RelatÃ³rio Final.md

---

## ğŸ“‚ Estrutura do RepositÃ³rio
# Estrutura de DiretÃ³rios â€” Projeto `qa-desafio-tecnico`

```plaintext
qa-desafio-tecnico/
â”‚
â”œâ”€â”€ api-testes/                 # AutomaÃ§Ã£o API
â”‚
â”œâ”€â”€ web-testes/                 # AutomaÃ§Ã£o Web (UI)
â”‚
â”œâ”€â”€ performance-testes/         # AutomaÃ§Ã£o de Performance
â”‚   â”œâ”€â”€ scripts/                # scripts K6
â”‚   â”‚   â”œâ”€â”€ stress-test-normal.js          # PERF-001
â”‚   â”‚   â”œâ”€â”€ stress-test-breakpoint.js      # PERF-002
â”‚   â”‚
â”‚   â”œâ”€â”€ results/                # resultados brutos das execuÃ§Ãµes
â”‚   â”‚   â”œâ”€â”€ stress-test-normal-result.txt
â”‚   â”‚   â”œâ”€â”€ stress-test-normal-summary.json
â”‚   â”‚   â”œâ”€â”€ stress-test-breakpoint-result.txt
â”‚   â”‚   â”œâ”€â”€ stress-test-breakpoint-summary.json
â”‚   â”‚
â”‚   â”œâ”€â”€ reports/                # relatÃ³rios interpretados
â”‚   â”‚   â”œâ”€â”€ REPORT-PERF-001.md
â”‚   â”‚   â”œâ”€â”€ REPORT-PERF-002.md
â”‚   â”‚
â”‚   â””â”€â”€ casos/                  # casos de teste em markdown
â”‚       â”œâ”€â”€ perf-stress-normal.md     # PERF-001
â”‚       â”œâ”€â”€ perf-stress-breakpoint.md # PERF-002
â”‚
â”œâ”€â”€ docs/                       # DocumentaÃ§Ã£o geral
â”‚   â”œâ”€â”€ Plano de Testes.docx
â”‚   â”œâ”€â”€ RelatÃ³rio Final.md
â”‚   â”œâ”€â”€ Casos de teste/
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ web/
â”‚   |
â”‚   â”‚
â”‚   â”œâ”€â”€ Bugs encontrados/
â”‚   â”‚
â”‚   â””â”€â”€ Evidencias/
```
---

## ğŸš€ Tecnologias e Ferramentas
- **Linguagem**: Java 17  
- **AutomaÃ§Ã£o Web**: Selenium + JUnit + Page Object Model  
- **AutomaÃ§Ã£o API**: RestAssured + JSON Schema Validator  
- **Performance**: k6  

---

# ğŸ“‘ RelatÃ³rio Final â€” Desafio TÃ©cnico de QA

Este relatÃ³rio apresenta as atividades realizadas durante o desafio tÃ©cnico, contemplando **testes de API (DummyJSON)**, **testes Web (Automation Testing Demo)** e **testes de performance (JSONPlaceholder)**.  

---

## ğŸ”¹ Parte 1 â€” Testes de API (DummyJSON)

### 1. ExploraÃ§Ã£o manual
- Realizei testes manuais no **Postman**, com o objetivo de entender os **endpoints**, formatos de resposta e limitaÃ§Ãµes.  
- Validei endpoints relacionados a **CRUD de produtos e usuÃ¡rios**.  
- Efetuei checagem de **contratos (JSON Schema)** e consistÃªncia de dados.

### 2. DefiniÃ§Ã£o de casos de teste
- Casos de teste manuais documentados com critÃ©rios claros.  
- Arquivos:
  - `qa-desafio-tecnico/docs/Casos de teste/api/casos-de-teste-api-produtos.md`
  - `qa-desafio-tecnico/docs/Casos de teste/api/casos-de-teste-api-usuarios.md`

### 3. Schemas JSON
- GeraÃ§Ã£o e definiÃ§Ã£o de **schemas JSON** para validaÃ§Ã£o de contrato.  
- Arquivos armazenados em:  
  - `qa-desafio-tecnico/evidencias/api/schemas`

### 4. AutomaÃ§Ã£o
- CriaÃ§Ã£o de automaÃ§Ã£o dos casos de teste utilizando **RestAssured + JUnit**.  

### 5. RelatÃ³rios
- IntegraÃ§Ã£o da automaÃ§Ã£o com **Allure Reports**, permitindo visualizaÃ§Ã£o detalhada dos resultados.

---

## ğŸ”¹ Parte 2 â€” Testes Web (Automation Testing Demo)

### 1. ExploraÃ§Ã£o manual
- Explorei a aplicaÃ§Ã£o **https://demo.automationtesting.in/** para entender as funcionalidades a serem validadas.  
- Funcionalidades mapeadas:  
  - Cadastro de usuÃ¡rio (formulÃ¡rio)  
  - Login de usuÃ¡rio  
  - InteraÃ§Ã£o com alertas  
  - Upload de arquivos  
  - ManipulaÃ§Ã£o de frames  

### 2. Casos de teste
- Casos de teste manuais documentados.  
- Arquivos:  
  - `qa-desafio-tecnico/docs/Casos de teste/web/casos-de-teste-web-cadastro.md`  
  - `qa-desafio-tecnico/docs/Casos de teste/web/casos-de-teste-web-login.md`  
  - `qa-desafio-tecnico/docs/Casos de teste/web/casos-de-teste-web-alertas.md`  
  - `qa-desafio-tecnico/docs/Casos de teste/web/casos-de-teste-web-upload.md`  
  - `qa-desafio-tecnico/docs/Casos de teste/web/casos-de-teste-web-frames.md`

### 3. IdentificaÃ§Ã£o de bug
- Identificado **defeito no formulÃ¡rio de cadastro**: o campo **Country** nÃ£o exibe as opÃ§Ãµes no dropdown.  
- Isso impede o fluxo completo de cadastro e bloqueia o teste de login (jÃ¡ que depende de cadastro prÃ©vio).  
- Report do bug criado em:  
  - `qa-desafio-tecnico/docs/Bugs encontrados/web/UI-WEB-BUG-001-country-dropdown.md`  
- EvidÃªncias anexadas (screenshot do problema).

### 4. AutomaÃ§Ã£o
- CriaÃ§Ã£o da automaÃ§Ã£o de testes com **Selenium WebDriver + JUnit**, aplicando o padrÃ£o **Page Objects**.  
- Implementados cenÃ¡rios de cadastro, login, upload, alertas e frames.  
- ObservaÃ§Ãµes importantes:  
  - O teste automatizado de **cadastro** nÃ£o pode ser executado devido ao bug reportado.  
  - O teste de **login** tambÃ©m nÃ£o Ã© viÃ¡vel, pois depende do cadastro.  
  - Isso foi destacado diretamente no cÃ³digo da automaÃ§Ã£o.

---

## ğŸ”¹ Parte 3 â€” Testes de Performance (JSONPlaceholder)

### 1. Casos de teste criados
- **REPORT-PERF-001** â†’ Validar endpoint `/posts` com **1000 usuÃ¡rios simultÃ¢neos**.  
  - Resultado: Endpoint suportou a carga dentro dos critÃ©rios definidos.  
- **REPORT-PERF-002** â†’ Estressar endpoint `/posts` atÃ© falha.  
  - Resultado: Ponto de falha atingido em **2000 VUs**.  

### 2. RelatÃ³rios de performance
- DocumentaÃ§Ã£o dos resultados em arquivos Markdown.  
- ConclusÃ£o:  
  - O endpoint `/posts` suporta **1000 VUs** de forma estÃ¡vel.  
  - Recomenda-se considerar **1000 usuÃ¡rios simultÃ¢neos** como **limite seguro** para esse endpoint.

---

## ğŸ“Œ ConclusÃµes Gerais

- Foram contemplados **testes manuais, automatizados e de performance** em diferentes contextos (API, Web e Performance).  
- Todos os cenÃ¡rios foram documentados em **casos de teste estruturados**.  
- EvidÃªncias e relatÃ³rios foram gerados e armazenados no repositÃ³rio.  
- IdentificaÃ§Ã£o de um **bug crÃ­tico na aplicaÃ§Ã£o web** e documentaÃ§Ã£o adequada do mesmo.  
- A automaÃ§Ã£o foi estruturada de forma escalÃ¡vel (**Page Objects, RestAssured, Allure Reports, K6**).  

---

## ğŸ“Š RelatÃ³rios de AutomaÃ§Ã£o API (Allure)

Os testes de API possuem **relatÃ³rios visuais** com Allure.

- Para gerar e visualizar localmente:
```bash
mvn clean test
allure serve target/allure-results
```

- Os resultados brutos ficam em: qa-desafio-tecnico/api-testes/target/allure-results/

- O relatÃ³rio HTML serÃ¡ aberto automaticamente no navegador.

Caso queira apenas gerar a pasta com o relatÃ³rio:
```bash
allure generate target/allure-results -o target/allure-report
```
---

## âš¡ RelatÃ³rios de Testes de Performance

Os testes de performance foram executados com k6 e analisados a partir dos resultados obtidos.

ğŸ“ **Caminho dos relatÃ³rios interpretados**:
`qa-desafio-tecnico/performance-testes/reports/`

**Resultados principais**:

`REPORT-PERF-001.md`
 â†’ Endpoint `/posts` suportou 1000 usuÃ¡rios simultÃ¢neos dentro dos critÃ©rios de desempenho.

`REPORT-PERF-002.md`
 â†’ O ponto de falha foi identificado em 2000 VUs.

ğŸ“Œ **ConclusÃ£o**: recomenda-se considerar 1000 VUs como limite seguro para este endpoint.